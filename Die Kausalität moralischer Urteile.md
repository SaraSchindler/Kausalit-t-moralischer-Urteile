---
title: Die Kausalität moralischer Urteile
---
Wörter: 5000-6000

# Einleitung

Zentrale Fragen: Wie fällen wir moralische Urteile? Sind unsere moralischen Urteile aufgrund der Mechanismen, durch die wir sie fällen, für unzuverlässig zu erklären? Welche Auswirkungen haben neurowissenschaftliche Erklärungen unserer moralischen Urteile auf Moraltheorien? Stützen sie bestimmte Ansätze und widerlegen sie andere? Sollten neurowissenschaftliche Ergebnisse überhaupt in die philosophische Debatte einfliessen?

# Ergebnisse aus den Neurowissenschaften


## Biologische und kulturelle Ursprünge  moralischen Urteilens

Eine grosse Frage, die sich in Bezug auf unsere Fähigkeit, moralische Urteile zu fällen, stellt, ist die Frage nach dem Ursprung dieser Fähigkeit. Sind moralische Urteile in angeborenen Eigenschaften verwurzelt oder lassen sie sich vollständig durch erworbene kulturelle Eigenschaften erklären? Im 20. Jahrhundert fielen die Antworten der Wissenschaftler/innen auf diese Frage eher extrem aus. Während der Psychologe B. F. Skinner [-@skinnerFreedomDignity1971]  moralische Regeln als sozial bedingte Verhaltensmuster sah und der Meinung war, dass man Menschen dazu bringen könne, so ziemlich alles als moralisch richtig oder falsch zu beurteilen, wenn man nur die richtigen Verstärkungen gebrauchte, war der Biologe E. O. Wilson [-@wilsonSociobiologyNewSynthesis2000] der Ansicht, dass fast die gesamte menschliche Moral durch die Anwendung der Evolutionsbiologie verstanden werden könne. Zu Beginn des 21. Jahrhunderts begannen jedoch die meisten Wissenschaftler und Wissenschaftlerinnen auf dem Gebiet des moralischen Urteilens ein hybrides Modell zu bevorzugen, welches sowohl biologischen als auch kulturellen Faktoren eine Rolle zuweist [vgl. @riniMoralityCognitiveScience2015].

Ein Beispiel für einen solchen modernen Ansatz ist die *Moral Foundations theory* vom Psychologen Jonathan Haidt [-@haidtRighteousMindWhy2012]. Haidt hebt die Rolle kultureller Unterschiede bei der wissenschaftlichen Untersuchung von Moralität hervor. Ihm zufolge lassen sich alle dokumentierten moralischen Überzeugungen in eine Handvoll moralischer Unterbereiche einordnen, wie beispielsweise Schadensvermeidung, Gerechtigkeit (bei der Verteilung von Ressourcen), Respekt vor Autorität und Reinheit. Haidt argumentiert, dass moralische Unterschiede zwischen den Kulturen Unterschiede in der Gewichtung dieser Grundlagen widerspiegeln. Eine Kultur, die alle moralischen Intuitionen, die der menschliche Geist zu erfahren bereit ist, gleich gewichtet, würde Handlungsunfähigkeit riskieren, da jede Handlung mehrere widersprüchliche Intuitionen auslöst. Wenn ein Kind geboren wird, ist es bereit, in allen Bereichen moralische Intuitionen zu entwickeln, aber sein lokales kulturelles Umfeld betont im Allgemeinen nur ein oder zwei dieser Ethiken. Intuitionen innerhalb einer kulturell gewichteten Ethik werden stärker ausgebildet, während Intuitionen innerhalb einer nicht gewichteten Ethik schwächer ausgeprägt sind [vgl. @haidtEmotionalDogIts2001,827]. 
Solche *Maintenance-Loss-Modelle* sind auch in anderen Bereichen der menschlichen höheren Kognition dokumentiert worden. Es scheint ein Konstruktionsmerkmal von Säugetiergehirnen zu sein, dass ein Grossteil der neuronalen Entwicklung 'erfahrungserwartend' ist [vgl. @haidtEmotionalDogIts2001, 827] . Das heißt, es gibt entwicklungszeitlich festgelegte Perioden hoher neuraler Plastizität, als ob das Gehirn zu einem bestimmten Zeitpunkt bestimmte Arten von Erfahrung 'erwartet', um seine endgültige Verdrahtung zu steuern. Solche sensiblen Perioden sind in der Entwicklung der sensorischen Systeme [vgl. @hubelPeriodSusceptibilityPhysiological1970] und der Sprache [vgl. @johnsonCriticalPeriodEffects1989] gut dokumentiert.
Haidt besteht aber auch darauf, dass die Biologie eine wichtige Rolle bei der Erklärung moralischer Urteile spielt: er sieht jeden dieser moralischen Unterbereiche in einem bestimmten evolutionären Ursprung verwurzelt. Bereits 2001 schrieb er:

> It [the model he advocates] proposes that morality, like language, is a major evolutionary adaptation for an intensely social species, built into multiple regions of the brain and body, that is better described as emergent than as learned yet that requires input and shaping from a particular culture. Moral intuitions are therefore both innate and enculturated [@haidtEmotionalDogIts2001,826].

Haidts Theorie ist nach wie vor ziemlich umstritten, aber sie ist ein prominentes Beispiel dafür, dass zeitgenössische Wissenschaftler/innen sich darauf konzentrieren, polarisierte Antworten auf die Frage 'Biologie oder Kultur' zu vermeiden [vgl. @riniMoralityCognitiveScience2015].

## Rationale Überlegungen und Intuitionen in moralischen Urteilen

Eine entscheidende Frage ist, ob moralische Urteile aus bewussten Überlegungen und Reflexionen entstehen oder durch unbewusste und unmittelbare Impulse ausgelöst werden. In den 1970er und 1980er Jahren wurde die Forschung in der Moralpsychologie durch die Arbeiten von Lawrence Kohlberg dominiert, der eine stark rationalistische Konzeption des moralischen Urteilens vertrat  [vgl. @riniMoralityCognitiveScience2015]. Seit der Wende zum zwanzigsten Jahrhundert hat man sich aber von dieser Ansicht gelöst. Ein Wendepunkt war die Veröffentlichung von Jonathan Haidts Arbeit _The Emotional Dog and Its Rational Tail_ [-@haidtEmotionalDogIts2001]. Dort erörtert Haidt ein Phänomen, das er als _moral dumbfounding_ bezeichnet. Er stellte seinen Probanden provokative Geschichten vor, wie beispielsweise die folgende Geschichte von einem Bruder und einer Schwester, die bewusst Inzest betreiben:
> Julie and Mark are brother and sister. They are traveling together in France on summer vacation from college. One night they are staying alone in a cabin near the beach. They decide that it would be interesting and fun if they tried making love. At the very least it would be a new experience for each of them. Julie was already taking birth control pills, but Mark uses a condom too, just to be safe. They both enjoy making love, but they decide not to do it again. They keep that night as a special secret, which makes them feel even closer to each other. What do you think about that? Was it OK for them to make love? [@haidtEmotionalDogIts2001,814] 

Als die Probanden gebeten wurden, ihre moralischen Urteile zu dieser Geschichte zu erklären, nannten sie Gründe, die durch die Beschreibung der Geschichten ausgeschlossen zu sein scheinen - so sagten sie zum Beispiel, dass die inzestuösen Geschwister ein Kind mit gefährlichen Geburtsfehlern erzeugen könnten, obwohl die Geschichte deutlich macht, dass sie sehr vorsichtig waren und sogar doppelt verhüteten, um eine Empfängnis zu vermeiden. Als sie an diese Details erinnert wurden, revidierten die Probanden ihre moralischen Urteile nicht, sondern sie sagten Dinge wie: *'Ich weiss nicht, warum es falsch ist, es ist einfach so'*. Haidt sieht solche Aussagen als Beweis dafür, dass das rationalistische Modell moralischen Urteilens nicht zutreffen kann: wie sollte es erklären, dass jemand weiss, dass eine Handlung moralisch falsch ist, aber nicht warum, wenn moralische Urteile auf rationalen Überlegungen basieren? Haidt schlägt daher ein alternatives Modell vor: das sozial intuitionistische Modell [vgl. @haidtEmotionalDogIts2001, 814]. Dieses Modell besagt, dass wir moralische Urteile nicht durch rationale Überlegungen fällen, sondern die rationalen Überlegungen lediglich unser bereits gefälltes moralisches Urteil rationalisieren sollen. Das Modell ist insofern ein soziales Modell, als es die private Argumentation der Individuen in den Hintergrund rückt und stattdessen die Bedeutung sozialer und kultureller Einflüsse betont. Das Modell ist insofern ein intuitionistisches Modell, als es festhält, dass das moralische Urteil im Allgemeinen das Ergebnis von schnellen, automatischen Bewertungen (Intuitionen) ist [vgl. @haidtEmotionalDogIts2001,814]. Obwohl beim sozial intuitionistischen Modell der Fokus klar auf moralischen Intuitionen liegt, räumt Haidt rationalen, moralischen Überlegungen doch auch einen Platz ein. Folgende drei Funktionen würden rationale Überlegungen erfüllen [vgl. @haidtEmotionalDogIts2001,828-829]:

- Die erste Funktion ist, dass die (ex post facto) moralische Überlegung von Menschen eine kausale Wirkung haben kann - auf die Intuitionen anderer Menschen. Aus der Sicht der sozialen Intuitionisten ist das moralische Urteilsvermögen nicht nur eine einzelne Handlung, die im Verstand einer einzelnen Person stattfindet, sondern ein fortlaufender Prozess, der sich oft über einen längeren Zeitraum und über mehrere Personen erstreckt. Begründungen und Argumente können zirkulieren und Menschen beeinflussen, auch wenn sich Einzelne nur selten mit privaten moralischen Überlegungen beschäftigen.
- Die zweite Funktion ermöglicht es, dass Menschen manchmal private moralische Überlegungen für sich selbst anstellen können, insbesondere wenn ihre anfänglichen Intuitionen in Konflikt geraten. Abtreibung mag sich für viele Menschen falsch anfühlen, wenn sie an den Fötus denken, aber richtig, wenn sie ihre Aufmerksamkeit auf die Frau verlagern. Wenn konkurrierende Intuitionen gleich stark sind, gerät das Beurteilungssystem in eine Sackgasse. Unter solchen Umständen verwendet man Argumentation und Intuition zusammen, um die Blockade zu durchbrechen. Das heisst, wenn man ein Dilemma bewusst untersucht und sich dabei abwechselnd auf jede beteiligte Partei konzentriert, werden verschiedene Intuitionen ausgelöst, die zu verschiedenen widersprüchlichen Urteilen führen. Mit Hilfe der Vernunft kann dann für jedes Urteil eine Argumentation konstruiert werden. Wenn die Argumentation für eines der Urteile besser ist als für die anderen, wird sich das Urteil richtig anfühlen. #Kommentar: RE?
- Die dritte Funktion besteht darin, dass eine Person im Prinzip einfach durch reine rationale Überlegungen zu einem Urteil gelangen könnte, das ihrer ursprünglichen Intuition widerspricht. Haidt zufolge geschieht dies aber höchst selten. Die Tatsache, dass es dennoch vorkommt, reicht aber bereits aus, um zu zeigen, dass das reine moralische Schlussfolgern eine kausale Rolle beim Fällen moralischer Urteile spielen kann.

## Die Kausalstruktur moralischer Urteile

Wir können moralische Urteile auch auf ihre Kausalstruktur untersuchen.  Welche Faktoren sind psychologisch gesehen ausschlaggebend, um ein bestimmtes moralisches Urteil über einen bestimmten Fall zu fällen? Sind dies dieselben Faktoren, auf die sich Moralphilosophen berufen, wenn sie ethische Entscheidungen formell analysieren? Die empirische Forschung scheint etwas anderes zu suggerieren.

Beispielsweise scheint Absichtlichkeit ein wichtiger Faktor zu sein, wenn wir die Moralität einer Handlung beurteilen. Die meisten Philosophen sind davon ausgegangen, dass etwas, das eine Person getan hat, nur dann als moralisch richtig oder falsch bewertet werden kann, wenn die Person vorsätzlich gehandelt hat (zumindest in gewöhnlichen Fällen, wobei Fahrlässigkeit ausser Acht gelassen werden muss). Wenn Peter Anna absichtlich stolpern lässt, dann ist diese Handlung moralisch falsch, wenn Peter hingegen Anna versehentlich stolpern lässt, dann ist das lediglich bedauerlich. Es scheint also, die Beurteilung von Absicht müsse kausal vor der Beurteilung der Moralität einer Handlung stattfinden.  Das heisst, wenn ich eine potenziell moralisch relevante Situation beurteile, stelle ich zunächst fest, ob die betroffene Person absichtlich gehandelt hat, und dann nutze ich dieses Urteil als Input, um herauszufinden, ob das, was sie getan hat, moralisch falsch ist. 
Empirische Belege legen jedoch nahe, dass dieses einfache Modell falsch ist.  Eine bekannte Reihe von Studien über den Nebenwirkungseffekt (auch bekannt als der Knobe-Effekt, nach seinem Entdecker Joshua Knobe) scheint zu zeigen, dass die kausale Beziehung zwischen moralischem Urteil und Absichtsurteil viel komplizierter ist. Joshua Knobe liess seine Probanden eine Kurzgeschichte wie die folgende lesen: 

> The vice-president of a company went to the chairman of the board and said, “We are thinking of starting a new program. It will help us increase profits, but it will also harm the environment.” The chairman of the board answered, “I don’t care at all about harming the environment. I just want to make as much profit as I can. Let’s start the new program.” They started the new program. Sure enough, the environment was harmed. [@knobeIntentionalActionSide2003,191]

Andere Teilnehmer lasen die gleiche Geschichte, nur dass das Programm als Nebeneffekt der Umwelt eher _helfen_ als schaden würde. Beide Teilnehmergruppen wurden gefragt, ob die Führungskraft den Nebeneffekt absichtlich herbeigeführt habe. Auffallend war, dass 82% der Probanden dachten, dass der Nebeneffekt absichtlich herbeigeführt wurde, wenn die Nebenwirkung moralisch falsch war (die Umwelt zu schädigen), aber wenn die Nebenwirkung moralisch gut war (der Umwelt zu helfen), dachten 77% der Probanden, dass der Nebeneffekt _nicht_ absichtlich herbeigeführt wurde [vgl. @knobeIntentionalActionSide2003,192]. Dieses Experiment (die Befunde wurden in vielen anderen Studien repliziert) legt nahe, dass die kausale Beziehung zwischen der Bewertung der Absichtlichkeit und dem moralischen Urteil nicht unidirektional ist. Menschen fällen manchmal moralische Urteile, bevor sie die Absichtlichkeit beurteilen. Anstatt dass die Beurteilung der Absichtlichkeit immer ein Input für die moralische Beurteilung ist, ist die moralische Beurteilung manchmal ein Input für die Beurteilung der Absichtlichkeit. Eine Nebenwirkung, die als falsch beurteilt wird, wird mit grösserer Wahrscheinlichkeit als absichtlich beurteilt als eine, die als moralisch richtig beurteilt wird.

#Kommentar: evtl. hier noch etwas ausbauen? Es geht ja hier um die Kausalität moralischer Urteile




## Die Neuroanatomie moralischer Urteile

Ein besonders zentrales Anliegen in dieser Literatur ist die Rolle der Emotionen bei moralischen Urteilen. Eine frühe einflussreiche Studie von Jorge Moll und Kollegen (2005) zeigte eine selektive Aktivität für moralische Urteile in einem Netzwerk von Hirnarealen, die allgemein als zentral für die emotionale Verarbeitung angesehen werden. In dieser Arbeit wurde die funktionelle Magnetresonanztomographie (fMRI) eingesetzt, bei der ein starker Magnet verwendet wird, um eine visuelle Darstellung der relativen Niveaus der in verschiedenen Hirnarealen verwendeten zellulären Energie zu erzeugen. Der Einsatz der fMRI ermöglicht es den Forschern, eine nahezu Echtzeit-Darstellung der Gehirnaktivitäten zu erhalten, während das bewusste Subjekt Urteile über moralisch wichtige Szenarien fällt. Eine äußerst einflussreiche fMRI-Studie zur moralischen Beurteilung wurde von Joshua D. Greene und Kollegen durchgeführt. Sie verglichen die Hirnaktivität von Menschen, die deontologische moralische Urteile fällen, mit der Hirnaktivität von Menschen, die utilitaristische moralische Urteile fällen. In einer Reihe von empirischen Studien und philosophischen Abhandlungen hat Greene argumentiert, dass seine Ergebnisse zeigen, dass utilitaristische moralische Beurteilung mit der Aktivität in kognitiven oder rationalen Hirnarealen korreliert, während deontologische moralische Beurteilung mit der Aktivität in emotionalen Bereichen korreliert (Greene 2008). (Seither hat er diese Ansicht etwas abgeschwächt und eingeräumt, dass beide Arten moralischer Beurteilung eine Form der emotionalen Verarbeitung zulassen. Er vertritt nun die Auffassung, dass deontologische Emotionen ein Typ sind, der automatische Verhaltensreaktionen auslöst, während utilitaristische Emotionen flexible Aufforderungen zur Deliberation sind (Greene 2014)). Laut Greene gibt uns das Erlernen dieser psychologischen Fakten Grund, unseren deontologischen Urteilen zu misstrauen; in Wirklichkeit ist es ein neurowissenschaftlich fundiertes Argument für den Utilitarismus. Dieses Argument steht im Mittelpunkt einer immer noch sehr lebhaften Debatte.


# Die Auswirkungen dieser Ergebnisse der Neurowissenschaften auf Moraltheorien

a) es gibt keine Auswirkungen, wir sollten diese Ergebnisse ignorieren
b) juhu, alles schön zusammenführen



# Konklusion
